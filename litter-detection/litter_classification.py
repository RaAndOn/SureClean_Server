# -*- coding: utf-8 -*-
"""Litter_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15xJvQNVpAeQJtRn_qvuYwQ8RKDaoyK8s

## This notebook is developed as part of Project SureClean - Litter Identification step. The script will take-in 30x30 image patches and classify the patch as litter or not litter. This script takes a deep learning approach to achieve the classification task

### **Mount Drive**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd 'drive/My Drive/Sureclean/Classifier_DL'

"""### **Import Modules**"""

import os
import numpy as np
from PIL import Image
import time

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

"""### **Global Configuration and Hyper Parameters**"""

class Configuration:
    load_data_from_dataset = True
    batch_size = 32
    num_workers = 0
    model_file_name = 'checkpoint'
    load_model_to_only_test = False
    load_model_to_train_and_test = False
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class hyper_parameters:
    closs_weight = 1
    lr_cent = 0.5
    num_epochs = 40
    learningRate = 1e-3
    weightDecay = 4e-5
    learningRateDecay = 0.72

hyper_params = hyper_parameters()
config = Configuration()
print('Device:',config.device)

"""### **Data Loader**"""

class ImageDataset(Dataset):
    def __init__(self, file_list, target_list):
        try:
            self.n_class = len(set(target_list))
            self.file_list = file_list
            self.target_list = torch.tensor(np.asarray(target_list,dtype=np.long))
        except:
            print('Error while processing dataset')

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, index):
        try:
            img = Image.open(self.file_list[index])
            # img = img.resize((32,32), Image.ANTIALIAS)
            img = torchvision.transforms.ToTensor()(img).to(config.device)
            label = self.target_list[index].to(config.device)
            # print(self.file_list[index],'\t',img.size())
            return img, label
        except:
            print('Error while loading',self.file_list[index])


#------  Parse the given directory to accumulate all the images  #------

def parse_data(datadir):
    img_list = []
    label_list = []
    for root, directories, filenames in os.walk(datadir):
        for filename in filenames:
            if filename.endswith('.jpg') or filename.endswith('.png'):
                filei = os.path.join(root, filename)
                img_list.append(filei)
                if root.split('/')[-1] == 'pos':
                    label_list.append(1)
                else:
                    label_list.append(0)

    class_n = len(set(label_list))
    print("Num of Images:",len(img_list),"|| Num of Labels:",len(label_list), "|| Classes of Labels:",class_n)

    return img_list, label_list, class_n

"""### **Load Pretrained Model**"""

if config.load_model_to_train_and_test or config.load_model_to_only_test:
    print('Loading....',config.model_file_name)
    checkpoint = torch.load(config.model_file_name,map_location=torch.device(config.device))
    network = checkpoint['network']
    network.load_state_dict(checkpoint['network_state_dict'])
    optimizer_label = checkpoint['optimizer_label']
    optimizer_label.load_state_dict(checkpoint['optimizer_label_state_dict'])
    optimizer_closs = checkpoint['optimizer_closs']
    optimizer_closs.load_state_dict(checkpoint['optimizer_closs_state_dict'])
    train_loss = checkpoint['loss']

"""### **Load Train, Validation and Test DataLoaders**"""

if not config.load_model_to_only_test:
    # Train Data
    img_list, label_list, class_n = parse_data('data/train/')
    train_dataset = ImageDataset(img_list, label_list)
    train_data_item, train_data_label = train_dataset.__getitem__(0)
    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)
    print('shape of one train data:', train_data_item.shape, '|| Class of one train label:', train_data_label)

    # Validation Data
    img_list, label_list, class_n = parse_data('data/validation/')
    dev_dataset = ImageDataset(img_list, label_list)
    dev_data_item, dev_data_label = dev_dataset.__getitem__(0)
    dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)
    print('shape of one dev data:', dev_data_item.shape, '|| Class of one dev label:', dev_data_label)


img_list, label_list, class_n = parse_data('data/test')
test_dataset = ImageDataset(img_list, label_list)
test_data_item, test_data_label = test_dataset.__getitem__(0)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)
print('shape of one test data:', test_data_item.shape, '|| Class of one test label:', test_data_label)

"""### **CenterLoss**"""

class CenterLoss(nn.Module):
    """
    Args:
        num_classes (int): number of classes.
        feat_dim (int): feature dimension.
    """
    def __init__(self, num_classes, feat_dim, device=torch.device('cpu')):
        super(CenterLoss, self).__init__()
        self.num_classes = num_classes
        self.feat_dim = feat_dim
        self.device = device
        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).to(self.device))

    def forward(self, x, labels):
        """
        Args:
            x: feature matrix with shape (batch_size, feat_dim).
            labels: ground truth labels with shape (batch_size).
        """
        batch_size = x.size(0)
        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \
                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()
        distmat.addmm_(1, -2, x, self.centers.t())

        classes = torch.arange(self.num_classes).long().to(self.device)
        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)
        mask = labels.eq(classes.expand(batch_size, self.num_classes))

        dist = []
        for i in range(batch_size):
            value = distmat[i][mask[i]]
            value = value.clamp(min=1e-12, max=1e+12) # for numerical stability
            dist.append(value)
        dist = torch.cat(dist)
        loss = dist.mean()

        return loss

"""### **MobileNetV2 Architecture**"""

class BasicBlock(nn.Module):

    def __init__(self, channel_size, stride=1, expansion_factor=6):
        super(BasicBlock, self).__init__()
        expansion_channel = expansion_factor*channel_size
        self.conv1 = nn.Conv2d(channel_size, expansion_channel, kernel_size=1, stride=1, bias=False)
        self.conv2 = nn.Conv2d(expansion_channel, expansion_channel, kernel_size=3, stride=stride, padding=1, groups=expansion_channel, bias=False)
        self.conv3 = nn.Conv2d(expansion_channel, channel_size, kernel_size=1, stride=1, bias=False)
        self.shortcut = nn.Conv2d(channel_size, channel_size, kernel_size=1, stride=stride, bias=False)

    def forward(self, x):
        
        out = F.relu6(self.conv1(x))
        out = F.relu6(self.conv2(out))
        out = F.relu6(self.conv3(out))
        out += self.shortcut(x)
        out = F.relu6(out)
        return out

#------  CNN Model with Residual Block #------  

class Network(nn.Module):

    def __init__(self, num_feats, hidden_sizes, num_classes, strides, repeatitions, feat_dim=10):
        super(Network, self).__init__()
        self.hidden_sizes = [num_feats] + hidden_sizes + [num_classes]
        self.repeatitions = [1] + repeatitions
        self.strides = [2] + strides
        self.layers = []
        self.num_layers = len(self.hidden_sizes)
        
        # ** Hidden Layers ** 
        for idx in range(self.num_layers-2):

            
            if idx>0 and idx<self.num_layers-2:
                # ** All Bottle Neck Layers **
                repeat_count = 0
                while repeat_count < self.repeatitions[idx]:
                    self.layers.append(BasicBlock(channel_size=self.hidden_sizes[idx],expansion_factor=6))
                    repeat_count += 1
                
            # ** Convolutions **
            self.layers.append(nn.Conv2d(in_channels=self.hidden_sizes[idx], out_channels=self.hidden_sizes[idx+1], kernel_size=3, stride=self.strides[idx], padding=1, bias=False))

            self.layers.append(nn.BatchNorm2d(self.hidden_sizes[idx+1]))
            self.layers.append(nn.ReLU6(inplace=True))
          

        self.layers = nn.Sequential(*self.layers)
        self.linear_label = nn.Linear(self.hidden_sizes[-2], self.hidden_sizes[-1], bias=False)
        
        # For creating the embedding to be passed into the Center Loss criterion
        self.linear_closs = nn.Linear(self.hidden_sizes[-2], feat_dim, bias=False)
        self.relu_closs = nn.ReLU(inplace=True)
        print(self.layers)

    
    def forward(self, x, evalMode=False):
        output = x
        output = self.layers(output)
            
        output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)
        output = output.reshape(output.shape[0], output.shape[1])
        embeddings = output
        
        label_output = self.linear_label(output)
        label_output = label_output/torch.norm(self.linear_label.weight, dim=1)
        
        if not evalMode:
            # Create the feature embedding for the Center Loss
            closs_output = self.linear_closs(output)
            closs_output = self.relu_closs(closs_output)
            return closs_output, label_output
        else:
            return output, label_output


def init_weights(m):
    if type(m) == nn.Conv2d or type(m) == nn.Linear:
        torch.nn.init.xavier_normal_(m.weight.data)

"""### **Training**"""

def train_closs(model, train_data_loader, validation_data_loader, learning_rate_decay):
    model.train()
    milestone_list  = list(range(0,hyper_params.num_epochs,2))
    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_label, milestones=milestone_list, gamma=learning_rate_decay)

    for epoch in range(hyper_params.num_epochs):
        avg_loss = 0.0
        epoch_start = time.time()
        loop_start = time.time()
        for batch_num, (feats, labels) in enumerate(train_data_loader):
            # feats,labels = feats.to(config.device),labels.to(config.device)
            # Reset the weights in each batch
            optimizer_label.zero_grad()
            optimizer_closs.zero_grad()
            
            # Forward pass through model
            feature, outputs = model(feats,evalMode=False)

            # Loss calculation
            l_loss = criterion_label(outputs, labels.long())
            c_loss = criterion_closs(feature, labels.long())
            loss = l_loss + hyper_params.closs_weight * c_loss
            
            # Backpropagation
            loss.backward()
            
            # Update weights
            scheduler.step()
            optimizer_label.step()
            # by doing so, weight_cent would not impact on the learning of centers
            for param in criterion_closs.parameters():
                param.grad.data *= (1. / hyper_params.closs_weight)
            optimizer_closs.step()
            
            avg_loss += loss.item()

            if batch_num % 10 == 0:
                print('Epoch: {} | Batch: {} | Avg-Loss: {:.4f} | Time: {:.4f}s'.format(epoch+1, batch_num, avg_loss/500, time.time()-loop_start))
                avg_loss = 0.0  
                loop_start = time.time()

            torch.cuda.empty_cache()
            del feats
            del labels
            del loss

        #  Run Train accuracy and Validation Accuracy in every Epoch
        val_loss, val_acc = accuracy(model, validation_data_loader)
        train_loss, train_acc = accuracy(model, train_data_loader)

        print('Train Loss: {:.4f} | Train Accuracy: {:.4f} | Val Loss: {:.4f} | Val Accuracy: {:.4f} | Time: {:.4f}s'.
              format(train_loss, train_acc, val_loss, val_acc,time.time()-epoch_start))
        print('-'*50)

    # Save the model in every Epoch
    checkpoint = {'network': model,'network_state_dict': model.state_dict(),\
                  'optimizer_label' : optimizer_label,'optimizer_label_state_dict' : optimizer_label.state_dict(),\
                  'optimizer_closs' : optimizer_closs,'optimizer_closs_state_dict' : optimizer_closs.state_dict(),\
                   'loss':train_loss}
    torch.save(checkpoint, 'checkpoint')

    return model

"""### **Accuracy Calculation**"""

def accuracy(model, data_loader):
    model.eval()
    loss_list = []
    accuracy = 0
    total = 0

    for batch_num, (feats, labels) in enumerate(data_loader):
        # feats,labels = feats.to(config.device),labels.to(config.device)
        feature, outputs = model(feats)
        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)
        pred_labels = pred_labels.view(-1)
        
        l_loss = criterion_label(outputs, labels.long())
        c_loss = criterion_closs(feature, labels.long())
        loss = l_loss + hyper_params.closs_weight * c_loss
        
        # This step calculates how many predicted labels match the ground truth labels
        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()
        total += len(labels)
        loss_list.extend([loss.item()]*feats.size()[0])
        del feats
        del labels

    model.train()
    return np.mean(loss_list), accuracy/total

"""### **Setup Architecture and Loss**"""

if not config.load_model_to_only_test:
    num_classes = train_dataset.n_class
    feat_dim = 10

    if config.load_model_to_train_and_test:
        # Load pretrained model for further training
        print('***** Processing Pretrained Model *****')
    else:
        # Create Fresh Model  Else use the pre-trained model to train
        num_feats = 3
        repeatitions = [1, 4, 3, 2]
        # hidden_sizes = [64, 32, 256, 512, 1280]
        hidden_sizes = [32, 16, 64, 256, 1280]
        strides = [1, 2, 2, 1, 1]
        print('Number of classes:',num_classes)

        network = Network(num_feats, hidden_sizes, num_classes, strides, repeatitions, feat_dim)
        network.apply(init_weights)

    criterion_label = nn.CrossEntropyLoss()
    criterion_closs = CenterLoss(num_classes, feat_dim, config.device)
    optimizer_label = torch.optim.Adam(network.parameters(), lr=hyper_params.learningRate, weight_decay=hyper_params.weightDecay)
    optimizer_closs = torch.optim.Adam(criterion_closs.parameters(), lr=hyper_params.lr_cent)

"""### **Run Training Routine**"""

if not config.load_model_to_only_test:
    network.train()
    network.to(config.device)
    trained_model = train_closs(network, train_dataloader, dev_dataloader, hyper_params.learningRateDecay)
else:
    network.eval()
    trained_model = network.to(config.device)

"""### **Inference**"""

start = time.time()
test_loss, test_acc = accuracy(trained_model, test_dataloader)
end = time.time()
print('Test Loss: {:.4f} | Test Accuracy: {:.4f} | Time: {:.4f}s'.format(test_loss, test_acc,end-start))

